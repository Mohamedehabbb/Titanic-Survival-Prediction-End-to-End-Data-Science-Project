# Titanic-Survival-Prediction-End-to-End-Data-Science-Project
data science project
# ğŸš¢ Titanic Survival Prediction â€“ Endâ€‘toâ€‘End Data Science Project

## ğŸ“Œ Project Overview

The sinking of the Titanic is one of the most wellâ€‘known tragedies in history. In this project, we tackle a classic supervised machine learning problem: **predicting passenger survival** based on demographic and socioâ€‘economic features such as gender, age, ticket class, and family relationships onboard.

This repository presents a **complete, realâ€‘world Data Science workflow**, starting from raw CSV files and ending with model comparison, interpretation, and actionable insights. The focus is not only on model performance, but also on **clear reasoning, exploratory analysis, and systematic improvement**.

---

## ğŸ¯ Problem Statement

Given passenger information, the goal is to predict whether a passenger **survived (1)** or **did not survive (0)** the Titanic disaster.

This is a **binary classification problem**, where accuracy and model interpretability are key evaluation criteria.

---

## ğŸ“‚ Dataset Description

The dataset is provided by Kaggle and consists of three CSV files:

* **train.csv** â€“ Training data including the target variable `Survived`
* **test.csv** â€“ Test data without survival labels (used for final predictions)
* **gender_submission.csv** â€“ Example submission format

### Target Variable

* `Survived`: 0 = Did not survive, 1 = Survived

### Key Features

* `Pclass`: Passenger class (proxy for socioâ€‘economic status)
* `Sex`: Passenger gender
* `Age`: Age in years
* `SibSp`: Number of siblings/spouses aboard
* `Parch`: Number of parents/children aboard
* `Fare`: Ticket fare
* `Embarked`: Port of embarkation

---

## ğŸ§  Project Workflow & Methodology

This project follows a structured Data Science pipeline:

### 1ï¸âƒ£ Data Understanding & Initial Inspection

* Loaded raw CSV files
* Inspected data types, distributions, and missing values
* Identified key data quality issues (missing `Age`, `Cabin`, `Embarked`)

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

EDA was performed to uncover patterns and relationships between features and survival:

* **Survival distribution** to understand class balance
* **Gender vs Survival** revealing significantly higher survival rates for females
* **Passenger Class vs Survival** showing strong socioâ€‘economic influence
* **Age distribution** analysis
* **Fare vs Survival** comparison

ğŸ“Š Visualizations were used extensively to support dataâ€‘driven decisions.

---

### 3ï¸âƒ£ Data Cleaning & Preprocessing

Key preprocessing steps included:

* Handling missing values:

  * `Age` imputed using the median
  * `Embarked` filled with the most frequent category
* Removing lowâ€‘information features:

  * Dropped `Cabin`, `Name`, and `Ticket`
* Ensured consistent preprocessing for both training and test datasets

---

### 4ï¸âƒ£ Feature Engineering

To enhance model performance while preserving original column names, new features were introduced:

* **FamilySize** = `SibSp + Parch + 1`

This feature captures family presence onboard, which has a strong behavioral impact on survival probability.

---

### 5ï¸âƒ£ Encoding & Scaling

* Categorical variables (`Sex`, `Embarked`) were encoded using oneâ€‘hot encoding
* Numerical features were standardized using `StandardScaler` for models sensitive to feature scale

---

### 6ï¸âƒ£ Model Training

Multiple machine learning models were trained and evaluated to ensure robust comparison:

* Logistic Regression
* Support Vector Machine (SVM)
* Decision Tree
* Random Forest
* Naive Bayes

Each model was trained using the same data split to ensure fair evaluation.

---

### 7ï¸âƒ£ Model Evaluation

Models were evaluated using:

* Accuracy score
* Confusion matrix
* Precision, recall, and F1â€‘score

A comparative bar chart was used to visually summarize model performance.

---

### 8ï¸âƒ£ Ensemble Learning

To further improve stability and performance, a **Voting Classifier** was implemented by combining:

* Logistic Regression
* SVM
* Random Forest

The ensemble model leveraged the strengths of both linear and treeâ€‘based approaches, resulting in more balanced predictions.

---

## ğŸ“ˆ Key Results & Insights

* Gender and passenger class are the strongest predictors of survival
* Simple linear models performed competitively when paired with proper preprocessing
* Ensemble learning improved robustness and reduced model variance
* Feature engineering had a more noticeable impact than increasing model complexity

---

## âœ… Final Conclusion

This project demonstrates how a wellâ€‘structured Data Science approach can effectively solve a realâ€‘world classification problem. By combining thoughtful EDA, disciplined preprocessing, and systematic model comparison, we achieved strong predictive performance while maintaining interpretability.

The notebook reflects industryâ€‘level best practices and is suitable for:

* Data Science portfolios
* Technical interviews
* Educational reference

---

## ğŸš€ Future Work

Potential improvements to further enhance this project include:

* Hyperparameter tuning using GridSearchCV
* Advanced feature engineering (e.g., title extraction from names)
* Handling class imbalance with resampling techniques
* ROCâ€‘AUC and Precisionâ€‘Recall analysis
* Deploying the model as a web application

---

## ğŸ“Œ Author
Mohamed Ehab
Data Scientist | Machine Learning Enthusiast

Mohamed Ehab
Data Scientist | Machine Learning Enthusiast
